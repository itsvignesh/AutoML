{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# About this Kernel\n",
    "This is my first attempt to publish a kernel in Kaggle. I will try H2O AutoML  on this IEEE Fraud transaction dataset. Primary goal for me is to work on a dataset that has combination of features (numbers, categorical, datetime) and the features are not explanatory, so i could experiment with pre-processing & Feature engineering concepts\n",
    "\n",
    "\n",
    "## Credits\n",
    "1. Thanks to kernels submitted by tunguz. I have used some of the concepts in this Kernel\n",
    "https://www.kaggle.com/tunguz/ieee-with-h2o-automl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import os\n",
    "import gc\n",
    "import itertools\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.26.0.2\n",
      "Checking whether there is an H2O instance running at http://localhost:54321 ..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"1.8.0_222\"; OpenJDK Runtime Environment (build 1.8.0_222-8u222-b10-1~deb9u1-b10); OpenJDK 64-Bit Server VM (build 25.222-b10, mixed mode)\n",
      "  Starting server from /opt/conda/lib/python3.6/site-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpykvhvpp3\n",
      "  JVM stdout: /tmp/tmpykvhvpp3/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpykvhvpp3/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.26.0.2</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>19 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_unknownUser_757x8h</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>10.67 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>4</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.6 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.26.0.2\n",
       "H2O cluster version age:    19 days\n",
       "H2O cluster name:           H2O_from_python_unknownUser_757x8h\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    10.67 Gb\n",
       "H2O cluster total cores:    4\n",
       "H2O cluster allowed cores:  4\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:54321\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.6 final\n",
       "--------------------------  ---------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h2o\n",
    "print(h2o.__version__)\n",
    "from h2o.automl import H2OAutoML\n",
    "h2o.init(max_mem_size='12G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n",
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "train_transaction=h2o.import_file(\"../input/train_transaction.csv\")\n",
    "train_identity=h2o.import_file(\"../input/train_identity.csv\")\n",
    "test_transaction=h2o.import_file(\"../input/test_transaction.csv\")\n",
    "test_identity=h2o.import_file(\"../input/test_identity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= train_transaction.merge(train_identity, all_x=True)\n",
    "test= test_transaction.merge(test_identity, all_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((590540, 434),\n",
       " (590540, 394),\n",
       " (144233, 41),\n",
       " (506691, 433),\n",
       " (506691, 393),\n",
       " (141907, 41))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, train_transaction.shape,train_identity.shape, test.shape, test_transaction.shape, test_identity.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's treat the TransactionDT feature, per the dataset description given\n",
    "References: https://www.kaggle.com/wajihullahbaig/up-sampling-on-every-hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates an hour of the day feature, encoded as 0-23. \n",
    "train.hours=((train['TransactionDT']/(3600)).floor())%24\n",
    "test.hours=((test['TransactionDT']/(3600)).floor())%24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop TransactionDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['TransactionDT'], axis=1)\n",
    "X_test = test.drop(['TransactionDT'], axis=1)\n",
    "del train_transaction, train_identity, test_transaction, test_identity\n",
    "del train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find & tag categorical variables as H2O factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in X_train.columns:\n",
    "    if X_train[f].columns_by_type(coltype='categorical'): \n",
    "        X_train[f]=X_train[f].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in X_test.columns:\n",
    "    if X_test[f].columns_by_type(coltype='categorical'): \n",
    "        X_test[f]=X_test[f].asfactor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  TransactionID</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">    3.66355e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">    3.66355e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">    3.66355e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">    3.66355e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">    3.66355e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">    3.66355e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">    3.66356e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">    3.66356e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">    3.66356e+06</td></tr>\n",
       "<tr><td style=\"text-align: right;\">    3.66356e+06</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.pop('TransactionID')\n",
    "X_test.pop('TransactionID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=X_train.columns[1:]\n",
    "y='isFraud'\n",
    "X_train[y]=X_train[y].asfactor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets try H2O autoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n",
      "CPU times: user 1min 16s, sys: 6.37 s, total: 1min 22s\n",
      "Wall time: 5h 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "aml = H2OAutoML(max_models=20, seed=18, max_runtime_secs=18000)\n",
    "aml.train(x=x, y=y, training_frame=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 7.36 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                        </th><th style=\"text-align: right;\">     auc</th><th style=\"text-align: right;\">  logloss</th><th style=\"text-align: right;\">  mean_per_class_error</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>XGBoost_1_AutoML_20190815_132750</td><td style=\"text-align: right;\">0.949714</td><td style=\"text-align: right;\">0.0645525</td><td style=\"text-align: right;\">              0.184026</td><td style=\"text-align: right;\">0.123871</td><td style=\"text-align: right;\">0.015344</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24 ms, sys: 8 ms, total: 32 ms\n",
      "Wall time: 76.4 ms\n",
      "Model Details\n",
      "=============\n",
      "H2OXGBoostEstimator :  XGBoost\n",
      "Model Key:  XGBoost_1_AutoML_20190815_132750\n",
      "\n",
      "Model Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>number_of_trees</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>294.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    number_of_trees\n",
       "--  -----------------\n",
       "    294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.012254022382807357\n",
      "RMSE: 0.11069788788774318\n",
      "LogLoss: 0.052426083866701105\n",
      "Mean Per-Class Error: 0.08893829580432888\n",
      "AUC: 0.9712954488085428\n",
      "pr_auc: 0.8248278035302774\n",
      "Gini: 0.9425908976170856\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.24299590332576862: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>567965.0</td>\n",
       "<td>1912.0</td>\n",
       "<td>0.0034</td>\n",
       "<td> (1912.0/569877.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>5863.0</td>\n",
       "<td>14800.0</td>\n",
       "<td>0.2837</td>\n",
       "<td> (5863.0/20663.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>573828.0</td>\n",
       "<td>16712.0</td>\n",
       "<td>0.0132</td>\n",
       "<td> (7775.0/590540.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  -----------------\n",
       "0      567965  1912   0.0034   (1912.0/569877.0)\n",
       "1      5863    14800  0.2837   (5863.0/20663.0)\n",
       "Total  573828  16712  0.0132   (7775.0/590540.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2429959</td>\n",
       "<td>0.7919732</td>\n",
       "<td>197.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1363519</td>\n",
       "<td>0.7732145</td>\n",
       "<td>238.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.3544557</td>\n",
       "<td>0.8671714</td>\n",
       "<td>167.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.2897676</td>\n",
       "<td>0.9869526</td>\n",
       "<td>184.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9975189</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0016062</td>\n",
       "<td>1.0</td>\n",
       "<td>395.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9975189</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2429959</td>\n",
       "<td>0.7899714</td>\n",
       "<td>197.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0348421</td>\n",
       "<td>0.9070803</td>\n",
       "<td>317.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0536481</td>\n",
       "<td>0.9110617</td>\n",
       "<td>294.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.242996     0.791973  197\n",
       "max f2                       0.136352     0.773215  238\n",
       "max f0point5                 0.354456     0.867171  167\n",
       "max accuracy                 0.289768     0.986953  184\n",
       "max precision                0.997519     1         0\n",
       "max recall                   0.00160618   1         395\n",
       "max specificity              0.997519     1         0\n",
       "max absolute_mcc             0.242996     0.789971  197\n",
       "max min_per_class_accuracy   0.0348421    0.90708   317\n",
       "max mean_per_class_accuracy  0.0536481    0.911062  294"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  3.50 %, avg score:  3.50 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100010</td>\n",
       "<td>0.9296920</td>\n",
       "<td>28.5747476</td>\n",
       "<td>28.5747476</td>\n",
       "<td>0.9998307</td>\n",
       "<td>0.9725310</td>\n",
       "<td>0.9998307</td>\n",
       "<td>0.9725310</td>\n",
       "<td>0.2857765</td>\n",
       "<td>0.2857765</td>\n",
       "<td>2757.4747624</td>\n",
       "<td>2757.4747624</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200003</td>\n",
       "<td>0.5540379</td>\n",
       "<td>27.4180116</td>\n",
       "<td>27.9964286</td>\n",
       "<td>0.9593565</td>\n",
       "<td>0.7743777</td>\n",
       "<td>0.9795953</td>\n",
       "<td>0.8734627</td>\n",
       "<td>0.2741615</td>\n",
       "<td>0.5599381</td>\n",
       "<td>2641.8011628</td>\n",
       "<td>2699.6428594</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300014</td>\n",
       "<td>0.2109579</td>\n",
       "<td>17.3819633</td>\n",
       "<td>24.4580738</td>\n",
       "<td>0.6081951</td>\n",
       "<td>0.3482046</td>\n",
       "<td>0.8557882</td>\n",
       "<td>0.6983668</td>\n",
       "<td>0.1738373</td>\n",
       "<td>0.7337753</td>\n",
       "<td>1638.1963330</td>\n",
       "<td>2345.8073802</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400007</td>\n",
       "<td>0.1247861</td>\n",
       "<td>6.1224686</td>\n",
       "<td>19.8745606</td>\n",
       "<td>0.2142252</td>\n",
       "<td>0.1594791</td>\n",
       "<td>0.6954111</td>\n",
       "<td>0.5636563</td>\n",
       "<td>0.0612205</td>\n",
       "<td>0.7949959</td>\n",
       "<td>512.2468616</td>\n",
       "<td>1887.4560610</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.0922134</td>\n",
       "<td>3.1556123</td>\n",
       "<td>16.5309974</td>\n",
       "<td>0.1104149</td>\n",
       "<td>0.1066571</td>\n",
       "<td>0.5784198</td>\n",
       "<td>0.4722626</td>\n",
       "<td>0.0315540</td>\n",
       "<td>0.8265499</td>\n",
       "<td>215.5612283</td>\n",
       "<td>1553.0997435</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0419307</td>\n",
       "<td>1.3289455</td>\n",
       "<td>8.9299714</td>\n",
       "<td>0.0464998</td>\n",
       "<td>0.0601105</td>\n",
       "<td>0.3124598</td>\n",
       "<td>0.2661866</td>\n",
       "<td>0.0664473</td>\n",
       "<td>0.8929971</td>\n",
       "<td>32.8945458</td>\n",
       "<td>792.9971447</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.0275970</td>\n",
       "<td>0.6397909</td>\n",
       "<td>6.1665779</td>\n",
       "<td>0.0223863</td>\n",
       "<td>0.0337885</td>\n",
       "<td>0.2157686</td>\n",
       "<td>0.1887205</td>\n",
       "<td>0.0319895</td>\n",
       "<td>0.9249867</td>\n",
       "<td>-36.0209069</td>\n",
       "<td>516.6577941</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0204441</td>\n",
       "<td>0.3987804</td>\n",
       "<td>4.7246286</td>\n",
       "<td>0.0139533</td>\n",
       "<td>0.0236793</td>\n",
       "<td>0.1653148</td>\n",
       "<td>0.1474602</td>\n",
       "<td>0.0199390</td>\n",
       "<td>0.9449257</td>\n",
       "<td>-60.1219571</td>\n",
       "<td>372.4628563</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3000017</td>\n",
       "<td>0.0132612</td>\n",
       "<td>0.2439101</td>\n",
       "<td>3.2310389</td>\n",
       "<td>0.0085344</td>\n",
       "<td>0.0163867</td>\n",
       "<td>0.1130541</td>\n",
       "<td>0.1037685</td>\n",
       "<td>0.0243914</td>\n",
       "<td>0.9693171</td>\n",
       "<td>-75.6089887</td>\n",
       "<td>223.1038885</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0096156</td>\n",
       "<td>0.1374461</td>\n",
       "<td>2.4576538</td>\n",
       "<td>0.0048092</td>\n",
       "<td>0.0112692</td>\n",
       "<td>0.0859933</td>\n",
       "<td>0.0806441</td>\n",
       "<td>0.0137444</td>\n",
       "<td>0.9830615</td>\n",
       "<td>-86.2553933</td>\n",
       "<td>145.7653777</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0072721</td>\n",
       "<td>0.0813047</td>\n",
       "<td>1.9823840</td>\n",
       "<td>0.0028449</td>\n",
       "<td>0.0083739</td>\n",
       "<td>0.0693636</td>\n",
       "<td>0.0661901</td>\n",
       "<td>0.0081305</td>\n",
       "<td>0.9911920</td>\n",
       "<td>-91.8695252</td>\n",
       "<td>98.2383971</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0055680</td>\n",
       "<td>0.0406524</td>\n",
       "<td>1.6587620</td>\n",
       "<td>0.0014224</td>\n",
       "<td>0.0063821</td>\n",
       "<td>0.0580401</td>\n",
       "<td>0.0562221</td>\n",
       "<td>0.0040652</td>\n",
       "<td>0.9952572</td>\n",
       "<td>-95.9347626</td>\n",
       "<td>65.8762038</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0041930</td>\n",
       "<td>0.0271016</td>\n",
       "<td>1.4256677</td>\n",
       "<td>0.0009483</td>\n",
       "<td>0.0048615</td>\n",
       "<td>0.0498841</td>\n",
       "<td>0.0488848</td>\n",
       "<td>0.0027102</td>\n",
       "<td>0.9979674</td>\n",
       "<td>-97.2898417</td>\n",
       "<td>42.5667688</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0030411</td>\n",
       "<td>0.0150027</td>\n",
       "<td>1.2493346</td>\n",
       "<td>0.0005249</td>\n",
       "<td>0.0036012</td>\n",
       "<td>0.0437142</td>\n",
       "<td>0.0432244</td>\n",
       "<td>0.0015003</td>\n",
       "<td>0.9994676</td>\n",
       "<td>-98.4997338</td>\n",
       "<td>24.9334559</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0020314</td>\n",
       "<td>0.0038717</td>\n",
       "<td>1.1109498</td>\n",
       "<td>0.0001355</td>\n",
       "<td>0.0025311</td>\n",
       "<td>0.0388721</td>\n",
       "<td>0.0387029</td>\n",
       "<td>0.0003872</td>\n",
       "<td>0.9998548</td>\n",
       "<td>-99.6128345</td>\n",
       "<td>11.0949792</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0001482</td>\n",
       "<td>0.0014519</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000508</td>\n",
       "<td>0.0014262</td>\n",
       "<td>0.0349900</td>\n",
       "<td>0.0349752</td>\n",
       "<td>0.0001452</td>\n",
       "<td>1.0</td>\n",
       "<td>-99.8548130</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift        cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ----------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.010001                    0.929692           28.5747     28.5747            0.999831         0.972531    0.999831                    0.972531            0.285777        0.285777                   2757.47   2757.47\n",
       "    2        0.0200003                   0.554038           27.418      27.9964            0.959356         0.774378    0.979595                    0.873463            0.274162        0.559938                   2641.8    2699.64\n",
       "    3        0.0300014                   0.210958           17.382      24.4581            0.608195         0.348205    0.855788                    0.698367            0.173837        0.733775                   1638.2    2345.81\n",
       "    4        0.0400007                   0.124786           6.12247     19.8746            0.214225         0.159479    0.695411                    0.563656            0.0612205       0.794996                   512.247   1887.46\n",
       "    5        0.05                        0.0922134          3.15561     16.531             0.110415         0.106657    0.57842                     0.472263            0.031554        0.82655                    215.561   1553.1\n",
       "    6        0.1                         0.0419307          1.32895     8.92997            0.0464998        0.0601105   0.31246                     0.266187            0.0664473       0.892997                   32.8945   792.997\n",
       "    7        0.15                        0.027597           0.639791    6.16658            0.0223863        0.0337885   0.215769                    0.188721            0.0319895       0.924987                   -36.0209  516.658\n",
       "    8        0.2                         0.0204441          0.39878     4.72463            0.0139533        0.0236793   0.165315                    0.14746             0.019939        0.944926                   -60.122   372.463\n",
       "    9        0.300002                    0.0132612          0.24391     3.23104            0.00853442       0.0163867   0.113054                    0.103769            0.0243914       0.969317                   -75.609   223.104\n",
       "    10       0.4                         0.00961557         0.137446    2.45765            0.00480924       0.0112692   0.0859933                   0.0806441           0.0137444       0.983062                   -86.2554  145.765\n",
       "    11       0.5                         0.00727211         0.0813047   1.98238            0.00284485       0.00837389  0.0693636                   0.0661901           0.00813047      0.991192                   -91.8695  98.2384\n",
       "    12       0.6                         0.00556802         0.0406524   1.65876            0.00142243       0.00638211  0.0580401                   0.0562221           0.00406524      0.995257                   -95.9348  65.8762\n",
       "    13       0.7                         0.00419299         0.0271016   1.42567            0.000948285      0.00486145  0.0498841                   0.0488848           0.00271016      0.997967                   -97.2898  42.5668\n",
       "    14       0.8                         0.00304106         0.0150027   1.24933            0.000524943      0.0036012   0.0437142                   0.0432244           0.00150027      0.999468                   -98.4997  24.9335\n",
       "    15       0.9                         0.00203137         0.00387165  1.11095            0.000135469      0.00253108  0.0388721                   0.0387029           0.000387165     0.999855                   -99.6128  11.095\n",
       "    16       1                           0.000148188        0.00145187  1                  5.0801e-05       0.00142622  0.03499                     0.0349752           0.000145187     1                          -99.8548  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ModelMetricsBinomial: xgboost\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.015344034585027136\n",
      "RMSE: 0.12387104013863424\n",
      "LogLoss: 0.06455253337886936\n",
      "Mean Per-Class Error: 0.1168313306054698\n",
      "AUC: 0.9497138402960366\n",
      "pr_auc: 0.7395718311389637\n",
      "Gini: 0.8994276805920731\n",
      "Confusion Matrix (Act/Pred) for max f1 @ threshold = 0.22832163767654354: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>0</td>\n",
       "<td>566649.0</td>\n",
       "<td>3228.0</td>\n",
       "<td>0.0057</td>\n",
       "<td> (3228.0/569877.0)</td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>7488.0</td>\n",
       "<td>13175.0</td>\n",
       "<td>0.3624</td>\n",
       "<td> (7488.0/20663.0)</td></tr>\n",
       "<tr><td>Total</td>\n",
       "<td>574137.0</td>\n",
       "<td>16403.0</td>\n",
       "<td>0.0181</td>\n",
       "<td> (10716.0/590540.0)</td></tr></table></div>"
      ],
      "text/plain": [
       "       0       1      Error    Rate\n",
       "-----  ------  -----  -------  ------------------\n",
       "0      566649  3228   0.0057   (3228.0/569877.0)\n",
       "1      7488    13175  0.3624   (7488.0/20663.0)\n",
       "Total  574137  16403  0.0181   (10716.0/590540.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum Metrics: Maximum metrics at their respective thresholds\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>metric</b></td>\n",
       "<td><b>threshold</b></td>\n",
       "<td><b>value</b></td>\n",
       "<td><b>idx</b></td></tr>\n",
       "<tr><td>max f1</td>\n",
       "<td>0.2283216</td>\n",
       "<td>0.7108941</td>\n",
       "<td>201.0</td></tr>\n",
       "<tr><td>max f2</td>\n",
       "<td>0.1178662</td>\n",
       "<td>0.6994908</td>\n",
       "<td>246.0</td></tr>\n",
       "<tr><td>max f0point5</td>\n",
       "<td>0.4064965</td>\n",
       "<td>0.8020556</td>\n",
       "<td>152.0</td></tr>\n",
       "<tr><td>max accuracy</td>\n",
       "<td>0.3144134</td>\n",
       "<td>0.9825041</td>\n",
       "<td>175.0</td></tr>\n",
       "<tr><td>max precision</td>\n",
       "<td>0.9972471</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max recall</td>\n",
       "<td>0.0006041</td>\n",
       "<td>1.0</td>\n",
       "<td>399.0</td></tr>\n",
       "<tr><td>max specificity</td>\n",
       "<td>0.9972471</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0</td></tr>\n",
       "<tr><td>max absolute_mcc</td>\n",
       "<td>0.2697911</td>\n",
       "<td>0.7096837</td>\n",
       "<td>189.0</td></tr>\n",
       "<tr><td>max min_per_class_accuracy</td>\n",
       "<td>0.0289413</td>\n",
       "<td>0.8767874</td>\n",
       "<td>323.0</td></tr>\n",
       "<tr><td>max mean_per_class_accuracy</td>\n",
       "<td>0.0381378</td>\n",
       "<td>0.8831687</td>\n",
       "<td>311.0</td></tr></table></div>"
      ],
      "text/plain": [
       "metric                       threshold    value     idx\n",
       "---------------------------  -----------  --------  -----\n",
       "max f1                       0.228322     0.710894  201\n",
       "max f2                       0.117866     0.699491  246\n",
       "max f0point5                 0.406496     0.802056  152\n",
       "max accuracy                 0.314413     0.982504  175\n",
       "max precision                0.997247     1         0\n",
       "max recall                   0.000604072  1         399\n",
       "max specificity              0.997247     1         0\n",
       "max absolute_mcc             0.269791     0.709684  189\n",
       "max min_per_class_accuracy   0.0289413    0.876787  323\n",
       "max mean_per_class_accuracy  0.0381378    0.883169  311"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gains/Lift Table: Avg response rate:  3.50 %, avg score:  3.38 %\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>group</b></td>\n",
       "<td><b>cumulative_data_fraction</b></td>\n",
       "<td><b>lower_threshold</b></td>\n",
       "<td><b>lift</b></td>\n",
       "<td><b>cumulative_lift</b></td>\n",
       "<td><b>response_rate</b></td>\n",
       "<td><b>score</b></td>\n",
       "<td><b>cumulative_response_rate</b></td>\n",
       "<td><b>cumulative_score</b></td>\n",
       "<td><b>capture_rate</b></td>\n",
       "<td><b>cumulative_capture_rate</b></td>\n",
       "<td><b>gain</b></td>\n",
       "<td><b>cumulative_gain</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>1</td>\n",
       "<td>0.0100010</td>\n",
       "<td>0.9058957</td>\n",
       "<td>28.3085984</td>\n",
       "<td>28.3085984</td>\n",
       "<td>0.9905181</td>\n",
       "<td>0.9656710</td>\n",
       "<td>0.9905181</td>\n",
       "<td>0.9656710</td>\n",
       "<td>0.2831147</td>\n",
       "<td>0.2831147</td>\n",
       "<td>2730.8598408</td>\n",
       "<td>2730.8598408</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2</td>\n",
       "<td>0.0200003</td>\n",
       "<td>0.4436599</td>\n",
       "<td>24.3398377</td>\n",
       "<td>26.3243861</td>\n",
       "<td>0.8516511</td>\n",
       "<td>0.6980578</td>\n",
       "<td>0.9210905</td>\n",
       "<td>0.8318757</td>\n",
       "<td>0.2433819</td>\n",
       "<td>0.5264966</td>\n",
       "<td>2333.9837683</td>\n",
       "<td>2532.4386057</td></tr>\n",
       "<tr><td></td>\n",
       "<td>3</td>\n",
       "<td>0.0300014</td>\n",
       "<td>0.1960787</td>\n",
       "<td>13.1477713</td>\n",
       "<td>21.9319332</td>\n",
       "<td>0.4600406</td>\n",
       "<td>0.2928826</td>\n",
       "<td>0.7673985</td>\n",
       "<td>0.6522012</td>\n",
       "<td>0.1314911</td>\n",
       "<td>0.6579877</td>\n",
       "<td>1214.7771261</td>\n",
       "<td>2093.1933216</td></tr>\n",
       "<tr><td></td>\n",
       "<td>4</td>\n",
       "<td>0.0400007</td>\n",
       "<td>0.1245731</td>\n",
       "<td>6.1321484</td>\n",
       "<td>17.9823214</td>\n",
       "<td>0.2145639</td>\n",
       "<td>0.1543372</td>\n",
       "<td>0.6292016</td>\n",
       "<td>0.5277457</td>\n",
       "<td>0.0613173</td>\n",
       "<td>0.7193050</td>\n",
       "<td>513.2148408</td>\n",
       "<td>1698.2321443</td></tr>\n",
       "<tr><td></td>\n",
       "<td>5</td>\n",
       "<td>0.05</td>\n",
       "<td>0.0936588</td>\n",
       "<td>3.4605257</td>\n",
       "<td>15.0781590</td>\n",
       "<td>0.1210838</td>\n",
       "<td>0.1074379</td>\n",
       "<td>0.5275849</td>\n",
       "<td>0.4436899</td>\n",
       "<td>0.0346029</td>\n",
       "<td>0.7539080</td>\n",
       "<td>246.0525739</td>\n",
       "<td>1407.8159028</td></tr>\n",
       "<tr><td></td>\n",
       "<td>6</td>\n",
       "<td>0.1</td>\n",
       "<td>0.0435949</td>\n",
       "<td>1.6861056</td>\n",
       "<td>8.3821323</td>\n",
       "<td>0.0589969</td>\n",
       "<td>0.0619812</td>\n",
       "<td>0.2932909</td>\n",
       "<td>0.2528355</td>\n",
       "<td>0.0843053</td>\n",
       "<td>0.8382132</td>\n",
       "<td>68.6105599</td>\n",
       "<td>738.2132314</td></tr>\n",
       "<tr><td></td>\n",
       "<td>7</td>\n",
       "<td>0.15</td>\n",
       "<td>0.0285411</td>\n",
       "<td>0.8053042</td>\n",
       "<td>5.8565229</td>\n",
       "<td>0.0281776</td>\n",
       "<td>0.0350196</td>\n",
       "<td>0.2049198</td>\n",
       "<td>0.1802302</td>\n",
       "<td>0.0402652</td>\n",
       "<td>0.8784784</td>\n",
       "<td>-19.4695833</td>\n",
       "<td>485.6522931</td></tr>\n",
       "<tr><td></td>\n",
       "<td>8</td>\n",
       "<td>0.2</td>\n",
       "<td>0.0210373</td>\n",
       "<td>0.5536466</td>\n",
       "<td>4.5308039</td>\n",
       "<td>0.0193721</td>\n",
       "<td>0.0244261</td>\n",
       "<td>0.1585329</td>\n",
       "<td>0.1412792</td>\n",
       "<td>0.0276823</td>\n",
       "<td>0.9061608</td>\n",
       "<td>-44.6353385</td>\n",
       "<td>353.0803852</td></tr>\n",
       "<tr><td></td>\n",
       "<td>9</td>\n",
       "<td>0.3</td>\n",
       "<td>0.0135927</td>\n",
       "<td>0.3561922</td>\n",
       "<td>3.1392666</td>\n",
       "<td>0.0124632</td>\n",
       "<td>0.0168055</td>\n",
       "<td>0.1098430</td>\n",
       "<td>0.0997880</td>\n",
       "<td>0.0356192</td>\n",
       "<td>0.9417800</td>\n",
       "<td>-64.3807772</td>\n",
       "<td>213.9266644</td></tr>\n",
       "<tr><td></td>\n",
       "<td>10</td>\n",
       "<td>0.4</td>\n",
       "<td>0.0098160</td>\n",
       "<td>0.1969704</td>\n",
       "<td>2.4036926</td>\n",
       "<td>0.0068920</td>\n",
       "<td>0.0115284</td>\n",
       "<td>0.0841052</td>\n",
       "<td>0.0777231</td>\n",
       "<td>0.0196970</td>\n",
       "<td>0.9614770</td>\n",
       "<td>-80.3029570</td>\n",
       "<td>140.3692591</td></tr>\n",
       "<tr><td></td>\n",
       "<td>11</td>\n",
       "<td>0.5000017</td>\n",
       "<td>0.0074253</td>\n",
       "<td>0.1272785</td>\n",
       "<td>1.9484036</td>\n",
       "<td>0.0044535</td>\n",
       "<td>0.0085501</td>\n",
       "<td>0.0681747</td>\n",
       "<td>0.0638883</td>\n",
       "<td>0.0127281</td>\n",
       "<td>0.9742051</td>\n",
       "<td>-87.2721509</td>\n",
       "<td>94.8403603</td></tr>\n",
       "<tr><td></td>\n",
       "<td>12</td>\n",
       "<td>0.6</td>\n",
       "<td>0.0056560</td>\n",
       "<td>0.0885656</td>\n",
       "<td>1.6384359</td>\n",
       "<td>0.0030989</td>\n",
       "<td>0.0064961</td>\n",
       "<td>0.0573289</td>\n",
       "<td>0.0543231</td>\n",
       "<td>0.0088564</td>\n",
       "<td>0.9830615</td>\n",
       "<td>-91.1434400</td>\n",
       "<td>63.8435852</td></tr>\n",
       "<tr><td></td>\n",
       "<td>13</td>\n",
       "<td>0.7</td>\n",
       "<td>0.0042225</td>\n",
       "<td>0.0769491</td>\n",
       "<td>1.4153663</td>\n",
       "<td>0.0026925</td>\n",
       "<td>0.0049176</td>\n",
       "<td>0.0495237</td>\n",
       "<td>0.0472652</td>\n",
       "<td>0.0076949</td>\n",
       "<td>0.9907564</td>\n",
       "<td>-92.3050864</td>\n",
       "<td>41.5366321</td></tr>\n",
       "<tr><td></td>\n",
       "<td>14</td>\n",
       "<td>0.8</td>\n",
       "<td>0.0030380</td>\n",
       "<td>0.0517834</td>\n",
       "<td>1.2449185</td>\n",
       "<td>0.0018119</td>\n",
       "<td>0.0036137</td>\n",
       "<td>0.0435597</td>\n",
       "<td>0.0418087</td>\n",
       "<td>0.0051783</td>\n",
       "<td>0.9959348</td>\n",
       "<td>-94.8216619</td>\n",
       "<td>24.4918453</td></tr>\n",
       "<tr><td></td>\n",
       "<td>15</td>\n",
       "<td>0.9</td>\n",
       "<td>0.0020065</td>\n",
       "<td>0.0256497</td>\n",
       "<td>1.1094441</td>\n",
       "<td>0.0008975</td>\n",
       "<td>0.0025182</td>\n",
       "<td>0.0388195</td>\n",
       "<td>0.0374431</td>\n",
       "<td>0.0025650</td>\n",
       "<td>0.9984997</td>\n",
       "<td>-97.4350288</td>\n",
       "<td>10.9444149</td></tr>\n",
       "<tr><td></td>\n",
       "<td>16</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0000313</td>\n",
       "<td>0.0150027</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0005249</td>\n",
       "<td>0.0013912</td>\n",
       "<td>0.0349900</td>\n",
       "<td>0.0338379</td>\n",
       "<td>0.0015003</td>\n",
       "<td>1.0</td>\n",
       "<td>-98.4997338</td>\n",
       "<td>0.0</td></tr></table></div>"
      ],
      "text/plain": [
       "    group    cumulative_data_fraction    lower_threshold    lift       cumulative_lift    response_rate    score       cumulative_response_rate    cumulative_score    capture_rate    cumulative_capture_rate    gain      cumulative_gain\n",
       "--  -------  --------------------------  -----------------  ---------  -----------------  ---------------  ----------  --------------------------  ------------------  --------------  -------------------------  --------  -----------------\n",
       "    1        0.010001                    0.905896           28.3086    28.3086            0.990518         0.965671    0.990518                    0.965671            0.283115        0.283115                   2730.86   2730.86\n",
       "    2        0.0200003                   0.44366            24.3398    26.3244            0.851651         0.698058    0.921091                    0.831876            0.243382        0.526497                   2333.98   2532.44\n",
       "    3        0.0300014                   0.196079           13.1478    21.9319            0.460041         0.292883    0.767399                    0.652201            0.131491        0.657988                   1214.78   2093.19\n",
       "    4        0.0400007                   0.124573           6.13215    17.9823            0.214564         0.154337    0.629202                    0.527746            0.0613173       0.719305                   513.215   1698.23\n",
       "    5        0.05                        0.0936588          3.46053    15.0782            0.121084         0.107438    0.527585                    0.44369             0.0346029       0.753908                   246.053   1407.82\n",
       "    6        0.1                         0.0435949          1.68611    8.38213            0.0589969        0.0619812   0.293291                    0.252836            0.0843053       0.838213                   68.6106   738.213\n",
       "    7        0.15                        0.0285411          0.805304   5.85652            0.0281776        0.0350196   0.20492                     0.18023             0.0402652       0.878478                   -19.4696  485.652\n",
       "    8        0.2                         0.0210373          0.553647   4.5308             0.0193721        0.0244261   0.158533                    0.141279            0.0276823       0.906161                   -44.6353  353.08\n",
       "    9        0.3                         0.0135927          0.356192   3.13927            0.0124632        0.0168055   0.109843                    0.099788            0.0356192       0.94178                    -64.3808  213.927\n",
       "    10       0.4                         0.00981605         0.19697    2.40369            0.006892         0.0115284   0.0841052                   0.0777231           0.019697        0.961477                   -80.303   140.369\n",
       "    11       0.500002                    0.00742531         0.127278   1.9484             0.00445348       0.00855013  0.0681747                   0.0638883           0.0127281       0.974205                   -87.2722  94.8404\n",
       "    12       0.6                         0.00565601         0.0885656  1.63844            0.00309891       0.00649613  0.0573289                   0.0543231           0.00885641      0.983062                   -91.1434  63.8436\n",
       "    13       0.7                         0.00422253         0.0769491  1.41537            0.00269245       0.00491761  0.0495237                   0.0472652           0.00769491      0.990756                   -92.3051  41.5366\n",
       "    14       0.8                         0.00303805         0.0517834  1.24492            0.0018119        0.00361375  0.0435597                   0.0418087           0.00517834      0.995935                   -94.8217  24.4918\n",
       "    15       0.9                         0.00200646         0.0256497  1.10944            0.000897484      0.00251821  0.0388195                   0.0374431           0.00256497      0.9985                     -97.435   10.9444\n",
       "    16       1                           3.12727e-05        0.0150027  1                  0.000524943      0.00139119  0.03499                     0.0338379           0.00150027      1                          -98.4997  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross-Validation Metrics Summary: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>mean</b></td>\n",
       "<td><b>sd</b></td>\n",
       "<td><b>cv_1_valid</b></td>\n",
       "<td><b>cv_2_valid</b></td>\n",
       "<td><b>cv_3_valid</b></td>\n",
       "<td><b>cv_4_valid</b></td>\n",
       "<td><b>cv_5_valid</b></td></tr>\n",
       "<tr><td>accuracy</td>\n",
       "<td>0.9819487</td>\n",
       "<td>0.0005329</td>\n",
       "<td>0.9819995</td>\n",
       "<td>0.9812545</td>\n",
       "<td>0.9810682</td>\n",
       "<td>0.9822536</td>\n",
       "<td>0.9831680</td></tr>\n",
       "<tr><td>auc</td>\n",
       "<td>0.9497089</td>\n",
       "<td>0.0020966</td>\n",
       "<td>0.9487611</td>\n",
       "<td>0.9475157</td>\n",
       "<td>0.9501294</td>\n",
       "<td>0.9469238</td>\n",
       "<td>0.9552146</td></tr>\n",
       "<tr><td>err</td>\n",
       "<td>0.0180513</td>\n",
       "<td>0.0005329</td>\n",
       "<td>0.0180005</td>\n",
       "<td>0.0187456</td>\n",
       "<td>0.0189318</td>\n",
       "<td>0.0177465</td>\n",
       "<td>0.0168321</td></tr>\n",
       "<tr><td>err_count</td>\n",
       "<td>2132.0</td>\n",
       "<td>62.934887</td>\n",
       "<td>2126.0</td>\n",
       "<td>2214.0</td>\n",
       "<td>2236.0</td>\n",
       "<td>2096.0</td>\n",
       "<td>1988.0</td></tr>\n",
       "<tr><td>f0point5</td>\n",
       "<td>0.7657267</td>\n",
       "<td>0.0107897</td>\n",
       "<td>0.7635091</td>\n",
       "<td>0.7573285</td>\n",
       "<td>0.7448014</td>\n",
       "<td>0.7727382</td>\n",
       "<td>0.7902562</td></tr>\n",
       "<tr><td>f1</td>\n",
       "<td>0.7117601</td>\n",
       "<td>0.0088395</td>\n",
       "<td>0.7095628</td>\n",
       "<td>0.7012952</td>\n",
       "<td>0.7016280</td>\n",
       "<td>0.7108168</td>\n",
       "<td>0.7354976</td></tr>\n",
       "<tr><td>f2</td>\n",
       "<td>0.6649647</td>\n",
       "<td>0.0084980</td>\n",
       "<td>0.6627367</td>\n",
       "<td>0.6529822</td>\n",
       "<td>0.6631855</td>\n",
       "<td>0.6580830</td>\n",
       "<td>0.6878359</td></tr>\n",
       "<tr><td>lift_top_group</td>\n",
       "<td>28.291739</td>\n",
       "<td>0.1858696</td>\n",
       "<td>28.55268</td>\n",
       "<td>27.938843</td>\n",
       "<td>28.45192</td>\n",
       "<td>28.507492</td>\n",
       "<td>28.007763</td></tr>\n",
       "<tr><td>logloss</td>\n",
       "<td>0.0645525</td>\n",
       "<td>0.0013564</td>\n",
       "<td>0.0646966</td>\n",
       "<td>0.0667256</td>\n",
       "<td>0.0651040</td>\n",
       "<td>0.0652673</td>\n",
       "<td>0.0609693</td></tr>\n",
       "<tr><td>max_per_class_error</td>\n",
       "<td>0.3629294</td>\n",
       "<td>0.0087861</td>\n",
       "<td>0.3651919</td>\n",
       "<td>0.3756906</td>\n",
       "<td>0.3601850</td>\n",
       "<td>0.3729308</td>\n",
       "<td>0.3406489</td></tr>\n",
       "<tr><td>mcc</td>\n",
       "<td>0.7078431</td>\n",
       "<td>0.0092673</td>\n",
       "<td>0.7056329</td>\n",
       "<td>0.6974400</td>\n",
       "<td>0.6954142</td>\n",
       "<td>0.7085814</td>\n",
       "<td>0.7321473</td></tr>\n",
       "<tr><td>mean_per_class_accuracy</td>\n",
       "<td>0.815761</td>\n",
       "<td>0.0044387</td>\n",
       "<td>0.8146325</td>\n",
       "<td>0.8093025</td>\n",
       "<td>0.8165917</td>\n",
       "<td>0.8110609</td>\n",
       "<td>0.8272176</td></tr>\n",
       "<tr><td>mean_per_class_error</td>\n",
       "<td>0.1842390</td>\n",
       "<td>0.0044387</td>\n",
       "<td>0.1853675</td>\n",
       "<td>0.1906975</td>\n",
       "<td>0.1834083</td>\n",
       "<td>0.1889391</td>\n",
       "<td>0.1727824</td></tr>\n",
       "<tr><td>mse</td>\n",
       "<td>0.0153440</td>\n",
       "<td>0.0003445</td>\n",
       "<td>0.0153060</td>\n",
       "<td>0.0159809</td>\n",
       "<td>0.0155330</td>\n",
       "<td>0.0154159</td>\n",
       "<td>0.0144844</td></tr>\n",
       "<tr><td>precision</td>\n",
       "<td>0.8065569</td>\n",
       "<td>0.0132569</td>\n",
       "<td>0.8042738</td>\n",
       "<td>0.7999384</td>\n",
       "<td>0.7766618</td>\n",
       "<td>0.8203822</td>\n",
       "<td>0.8315283</td></tr>\n",
       "<tr><td>r2</td>\n",
       "<td>0.5454864</td>\n",
       "<td>0.0114977</td>\n",
       "<td>0.542257</td>\n",
       "<td>0.5300422</td>\n",
       "<td>0.5374317</td>\n",
       "<td>0.5408101</td>\n",
       "<td>0.5768913</td></tr>\n",
       "<tr><td>recall</td>\n",
       "<td>0.6370705</td>\n",
       "<td>0.0087861</td>\n",
       "<td>0.6348081</td>\n",
       "<td>0.6243094</td>\n",
       "<td>0.6398150</td>\n",
       "<td>0.6270691</td>\n",
       "<td>0.6593512</td></tr>\n",
       "<tr><td>rmse</td>\n",
       "<td>0.1238553</td>\n",
       "<td>0.0013982</td>\n",
       "<td>0.1237175</td>\n",
       "<td>0.1264157</td>\n",
       "<td>0.1246313</td>\n",
       "<td>0.1241608</td>\n",
       "<td>0.1203510</td></tr>\n",
       "<tr><td>specificity</td>\n",
       "<td>0.9944515</td>\n",
       "<td>0.0004426</td>\n",
       "<td>0.9944570</td>\n",
       "<td>0.9942955</td>\n",
       "<td>0.9933684</td>\n",
       "<td>0.9950526</td>\n",
       "<td>0.9950841</td></tr></table></div>"
      ],
      "text/plain": [
       "                         mean       sd           cv_1_valid    cv_2_valid    cv_3_valid    cv_4_valid    cv_5_valid\n",
       "-----------------------  ---------  -----------  ------------  ------------  ------------  ------------  ------------\n",
       "accuracy                 0.981949   0.000532859  0.982         0.981254      0.981068      0.982254      0.983168\n",
       "auc                      0.949709   0.00209656   0.948761      0.947516      0.950129      0.946924      0.955215\n",
       "err                      0.0180513  0.000532859  0.0180005     0.0187456     0.0189318     0.0177465     0.0168321\n",
       "err_count                2132       62.9349      2126          2214          2236          2096          1988\n",
       "f0point5                 0.765727   0.0107897    0.763509      0.757328      0.744801      0.772738      0.790256\n",
       "f1                       0.71176    0.00883946   0.709563      0.701295      0.701628      0.710817      0.735498\n",
       "f2                       0.664965   0.008498     0.662737      0.652982      0.663186      0.658083      0.687836\n",
       "lift_top_group           28.2917    0.18587      28.5527       27.9388       28.4519       28.5075       28.0078\n",
       "logloss                  0.0645525  0.00135637   0.0646966     0.0667256     0.065104      0.0652673     0.0609693\n",
       "max_per_class_error      0.362929   0.00878608   0.365192      0.375691      0.360185      0.372931      0.340649\n",
       "mcc                      0.707843   0.00926731   0.705633      0.69744       0.695414      0.708581      0.732147\n",
       "mean_per_class_accuracy  0.815761   0.00443871   0.814633      0.809302      0.816592      0.811061      0.827218\n",
       "mean_per_class_error     0.184239   0.00443871   0.185367      0.190698      0.183408      0.188939      0.172782\n",
       "mse                      0.015344   0.000344525  0.015306      0.0159809     0.015533      0.0154159     0.0144844\n",
       "precision                0.806557   0.0132569    0.804274      0.799938      0.776662      0.820382      0.831528\n",
       "r2                       0.545486   0.0114977    0.542257      0.530042      0.537432      0.54081       0.576891\n",
       "recall                   0.637071   0.00878608   0.634808      0.624309      0.639815      0.627069      0.659351\n",
       "rmse                     0.123855   0.00139822   0.123717      0.126416      0.124631      0.124161      0.120351\n",
       "specificity              0.994452   0.000442616  0.994457      0.994295      0.993368      0.995053      0.995084"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring History: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b></b></td>\n",
       "<td><b>timestamp</b></td>\n",
       "<td><b>duration</b></td>\n",
       "<td><b>number_of_trees</b></td>\n",
       "<td><b>training_rmse</b></td>\n",
       "<td><b>training_logloss</b></td>\n",
       "<td><b>training_auc</b></td>\n",
       "<td><b>training_pr_auc</b></td>\n",
       "<td><b>training_lift</b></td>\n",
       "<td><b>training_classification_error</b></td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-15 17:18:21</td>\n",
       "<td> 3:50:30.828</td>\n",
       "<td>0.0</td>\n",
       "<td>0.5</td>\n",
       "<td>0.6931472</td>\n",
       "<td>0.5</td>\n",
       "<td>0.0</td>\n",
       "<td>1.0</td>\n",
       "<td>0.9650100</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-15 17:19:10</td>\n",
       "<td> 3:51:19.484</td>\n",
       "<td>5.0</td>\n",
       "<td>0.3990506</td>\n",
       "<td>0.5089078</td>\n",
       "<td>0.8584484</td>\n",
       "<td>0.5365625</td>\n",
       "<td>27.2923923</td>\n",
       "<td>0.0258780</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-15 17:19:39</td>\n",
       "<td> 3:51:48.598</td>\n",
       "<td>10.0</td>\n",
       "<td>0.3237457</td>\n",
       "<td>0.3891882</td>\n",
       "<td>0.8681216</td>\n",
       "<td>0.5497315</td>\n",
       "<td>27.6069323</td>\n",
       "<td>0.0249890</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-15 17:20:08</td>\n",
       "<td> 3:52:17.842</td>\n",
       "<td>15.0</td>\n",
       "<td>0.2679009</td>\n",
       "<td>0.3065990</td>\n",
       "<td>0.8735695</td>\n",
       "<td>0.5714146</td>\n",
       "<td>27.8007591</td>\n",
       "<td>0.0241813</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-15 17:20:38</td>\n",
       "<td> 3:52:48.055</td>\n",
       "<td>20.0</td>\n",
       "<td>0.2271950</td>\n",
       "<td>0.2477767</td>\n",
       "<td>0.8779656</td>\n",
       "<td>0.5873875</td>\n",
       "<td>27.9456677</td>\n",
       "<td>0.0236919</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-15 17:49:35</td>\n",
       "<td> 4:21:45.182</td>\n",
       "<td>275.0</td>\n",
       "<td>0.1116261</td>\n",
       "<td>0.0532426</td>\n",
       "<td>0.9703236</td>\n",
       "<td>0.8224473</td>\n",
       "<td>28.5650695</td>\n",
       "<td>0.0134944</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-15 17:50:13</td>\n",
       "<td> 4:22:23.216</td>\n",
       "<td>280.0</td>\n",
       "<td>0.1113491</td>\n",
       "<td>0.0529982</td>\n",
       "<td>0.9705847</td>\n",
       "<td>0.8243650</td>\n",
       "<td>28.5650695</td>\n",
       "<td>0.0134233</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-15 17:50:51</td>\n",
       "<td> 4:23:01.119</td>\n",
       "<td>285.0</td>\n",
       "<td>0.1110139</td>\n",
       "<td>0.0527072</td>\n",
       "<td>0.9709737</td>\n",
       "<td>0.8260558</td>\n",
       "<td>28.5699085</td>\n",
       "<td>0.0132895</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-15 17:51:29</td>\n",
       "<td> 4:23:38.897</td>\n",
       "<td>290.0</td>\n",
       "<td>0.1108478</td>\n",
       "<td>0.0525688</td>\n",
       "<td>0.9711148</td>\n",
       "<td>0.8232781</td>\n",
       "<td>28.5747476</td>\n",
       "<td>0.0133979</td></tr>\n",
       "<tr><td></td>\n",
       "<td>2019-08-15 17:52:03</td>\n",
       "<td> 4:24:13.032</td>\n",
       "<td>294.0</td>\n",
       "<td>0.1106979</td>\n",
       "<td>0.0524261</td>\n",
       "<td>0.9712954</td>\n",
       "<td>0.8248278</td>\n",
       "<td>28.5747476</td>\n",
       "<td>0.0131659</td></tr></table></div>"
      ],
      "text/plain": [
       "     timestamp            duration     number_of_trees    training_rmse        training_logloss      training_auc        training_pr_auc     training_lift       training_classification_error\n",
       "---  -------------------  -----------  -----------------  -------------------  --------------------  ------------------  ------------------  ------------------  -------------------------------\n",
       "     2019-08-15 17:18:21  3:50:30.828  0.0                0.5                  0.6931471805599635    0.5                 0.0                 1.0                 0.9650099908558268\n",
       "     2019-08-15 17:19:10  3:51:19.484  5.0                0.39905057068310207  0.508907774125064     0.8584484049109776  0.5365625469416339  27.29239231169757   0.02587800995698852\n",
       "     2019-08-15 17:19:39  3:51:48.598  10.0               0.3237457408266889   0.3891882066143518    0.8681215792981729  0.5497314850519873  27.60693229401323   0.0249889931249365\n",
       "     2019-08-15 17:20:08  3:52:17.842  15.0               0.26790094137189424  0.3065989985673179    0.8735694926069537  0.5714146490649368  27.80075910119813   0.024181257831814948\n",
       "     2019-08-15 17:20:38  3:52:48.055  20.0               0.22719503085260706  0.2477766904755683    0.8779656124154683  0.5873875244012993  27.94566765958395   0.023691875232837743\n",
       "---  ---                  ---          ---                ---                  ---                   ---                 ---                 ---                 ---\n",
       "     2019-08-15 17:49:35  4:21:45.182  275.0              0.11162607300023768  0.05324259134007053   0.9703236073287946  0.8224473064358346  28.56506947091325   0.013494428827852473\n",
       "     2019-08-15 17:50:13  4:22:23.216  280.0              0.11134905135896132  0.05299823680824303   0.9705846807306837  0.8243649875586871  28.56506947091325   0.013423307481288312\n",
       "     2019-08-15 17:50:51  4:23:01.119  285.0              0.11101389881213394  0.05270722494881471   0.9709736899170256  0.8260558109794376  28.569908547564264  0.013289531615131913\n",
       "     2019-08-15 17:51:29  4:23:38.897  290.0              0.11084780698525298  0.0525687935929144    0.9711148183672236  0.8232780826786998  28.574747624215274  0.013397907000372541\n",
       "     2019-08-15 17:52:03  4:24:13.032  294.0              0.11069788788774318  0.052426083866701105  0.9712954488085428  0.8248278035302774  28.574747624215274  0.013165915941341822"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n",
      "Variable Importances: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>variable</b></td>\n",
       "<td><b>relative_importance</b></td>\n",
       "<td><b>scaled_importance</b></td>\n",
       "<td><b>percentage</b></td></tr>\n",
       "<tr><td>V258</td>\n",
       "<td>53418.6914062</td>\n",
       "<td>1.0</td>\n",
       "<td>0.0762291</td></tr>\n",
       "<tr><td>C1</td>\n",
       "<td>27081.8183594</td>\n",
       "<td>0.5069727</td>\n",
       "<td>0.0386461</td></tr>\n",
       "<tr><td>C14</td>\n",
       "<td>25638.4375000</td>\n",
       "<td>0.4799526</td>\n",
       "<td>0.0365863</td></tr>\n",
       "<tr><td>C13</td>\n",
       "<td>24125.9375000</td>\n",
       "<td>0.4516385</td>\n",
       "<td>0.0344280</td></tr>\n",
       "<tr><td>TransactionAmt</td>\n",
       "<td>21076.9648438</td>\n",
       "<td>0.3945616</td>\n",
       "<td>0.0300771</td></tr>\n",
       "<tr><td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td>\n",
       "<td>---</td></tr>\n",
       "<tr><td>V241</td>\n",
       "<td>1.5487251</td>\n",
       "<td>0.0000290</td>\n",
       "<td>0.0000022</td></tr>\n",
       "<tr><td>V110</td>\n",
       "<td>1.1257648</td>\n",
       "<td>0.0000211</td>\n",
       "<td>0.0000016</td></tr>\n",
       "<tr><td>id_12.missing(NA)</td>\n",
       "<td>0.8702278</td>\n",
       "<td>0.0000163</td>\n",
       "<td>0.0000012</td></tr>\n",
       "<tr><td>M1.T</td>\n",
       "<td>0.2701855</td>\n",
       "<td>0.0000051</td>\n",
       "<td>0.0000004</td></tr>\n",
       "<tr><td>P_emaildomain.bellsouth.net</td>\n",
       "<td>0.1240234</td>\n",
       "<td>0.0000023</td>\n",
       "<td>0.0000002</td></tr></table></div>"
      ],
      "text/plain": [
       "variable                     relative_importance    scaled_importance       percentage\n",
       "---------------------------  ---------------------  ----------------------  ----------------------\n",
       "V258                         53418.69140625         1.0                     0.0762290940856643\n",
       "C1                           27081.818359375        0.506972702745886       0.03864606985647968\n",
       "C14                          25638.4375             0.4799525564005167      0.03658634857851009\n",
       "C13                          24125.9375             0.45163849702947345     0.03442799348276775\n",
       "TransactionAmt               21076.96484375         0.39456160922137434     0.030077074031927258\n",
       "---                          ---                    ---                     ---\n",
       "V241                         1.5487251281738281     2.8992195192423358e-05  2.2100487750731845e-06\n",
       "V110                         1.1257648468017578     2.107436212243198e-05   1.6064795330262277e-06\n",
       "id_12.missing(NA)            0.8702278137207031     1.6290698832410676e-05  1.2418252140170551e-06\n",
       "M1.T                         0.2701854705810547     5.057882615024952e-06   3.855578097349829e-07\n",
       "P_emaildomain.bellsouth.net  0.1240234375           2.3217236183642124e-06  1.769828881451945e-07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "See the whole table with table.as_data_frame()\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "aml.leader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost prediction progress: |████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:70: UserWarning: Test/Validation dataset column 'DeviceInfo' has levels not trained on: [2014819, 2PS64, 4009A, 4027A, 4047A, 4047G, 5010G, 5011A, 5012G, 5015A, 5025G, 5026A, 5026A Build/NRD90M, 5033A, 5041C, 5044T, 5049W, 5049Z, 5052Y, 5054S, 5056A, 5058A, 5059A, 5080A, 5080X, 5085A, 5085B, 5086A, 5099A, 5099A Build/O00623, 6016A, 6036A Build/JLS36C, 6043A, 6045O, 6062W, 7040N, 7048A, 7048X, 8050G, 8080, 8082, 8_Plus, 9003A, 9024W, A10, A10 Pro Build/LMY47I, A1_PRO, A37fw, A462C, A502DL, A50LT, A622GL, A7, AGS-L03, AGS-L09, AGS-W09, ALCATELONETOUCH, ALE-L02, ALE-L21, ALE-L23, ALP-L09, ALP-L29, ANE-LX1, ANE-LX1 Build/HUAWEIANE-LX1, ANE-LX2, ANE-LX3, ASUS_A002A, ASUS_A006, ASUS_A007, ASUS_A009, ASUS_X008DC, ASUS_X00AD, ASUS_X00HD, ASUS_X00LDA, ASUS_X00PD, ASUS_Z00XS, ASUS_Z012DC, ASUS_Z017DC, ASUS_Z01HD, ASUS_Z01MD, ATU-L11, ATU-L21, ATU-LX3, ATU-LX3 Build/HUAWEIATU-LX3, AUM-L29, AW790, AX681, AX921, Alcatel_5044R, Alcatel_5098O, Alcatel_6060C, Alpha 950, Alumini_3_Plus, Android 8.0.0, Aquaris_M4.5, Armor, Astro, Azumi_DOSHI_A55_QL, Azumi_IRO_A5_Q, B1-850, BAC-L03, BAH-L09, BAH-W09, BBB100-1 Build/OPM1.171019.026, BBF100-2, BGO-DL09, BKL-L09, BLA-A09, BLA-A09 Build/HUAWEIBLA-A09, BLA-AL00, BLA-L09, BLA-L29, BLA-L29 Build/HUAWEIBLA-L29S, BLADE, BLADE A520, BLADE A6 MAX Build/N2G47H, BLADE A602, BLADE L7, BLADE V8 SE, BLADE V8Q, BLADE V9, BLADE V9 Build/OPR1.170623.032, BLL-L22, BLL-L23, BLN-L21, BLN-L24, BND-L21, BND-L24, BV6000S, Blade L2 Plus, Blade V580, Blade V6, Blade V6 Plus, Bluboo, C2105, C5, C6506, C6506 Build/10.7.A.0.222, C6902, CAM-L03, CAM-L21, CHC-U03, CLT-L04, CLT-L04 Build/HUAWEICLT-L04, CLT-L29, CLT-L29 Build/HUAWEICLT-L29, CMR-AL09, CMR-W09, CMR-W19, COL-L29, CPH1725, CPH1835, CPH1835 Build/O11019, CPU, CRO-L03, CUBOT_X18_Plus, Che2-L23, D2206, D2303, D5303, D5503 Build/14.6.A.0.368, D5803, D6653, DIG-L03, DLI-L22, DRA-L21, DRA-LX3, DRA-LX3 Build/HUAWEIDRA-LX3, DUO, E2306, E5306 Build/27.1.A.1.81, E5306 Build/27.3.A.0.173, E5603, E5663, E6782, E6883, E6910, EML-L09, EML-L09 Build/HUAWEIEML-L09, EML-L29, ENERGY, EV05, EVA-L09, EVA-L19, Energy, F3111, F3112, F3116, F3216, F5121 Build/34.4.A.2.107, FIG-LX1, FIG-LX1 Build/HUAWEIFIG-LX1, FIG-LX3, FLA-LX3, FLA-LX3 Build/HUAWEIFLA-LX3, FP1U, FRD-L04, FRD-L09, FRD-L19, Fedora, FunWebProducts, G24027K, G3112, G3121, G3121 Build/48.1.A.2.21, G3123 Build/48.1.A.2.21, G3123 Build/48.1.A.2.50, G3223 Build/48.1.A.2.21, G3223 Build/48.1.A.2.50, G3311, G3312, G3313 Build/43.0.A.7.55, G3313 Build/43.0.A.7.70, G3412, G8141 Build/47.1.A.12.270, G8231, G8232, G8441, GHIA_AXIS7, GHIA_AXIS7P, GLAM, GT-I8190L, GT-I9060I, GT-I9060L, GT-I9060M, GT-I9195 Build/KOT49H, GT-I9300I, GT-I9301I, GT-I9505, GT-N5120, GT-N8013, GT-S6810M, Galaxy, Gini s5Pro Build/NRD90M, Gravity, H3123, H3223, H3223 Build/50.1.A.10.40, H3311, H8216, H8314, HK-914581, HMA-L09, HS20502-16, HTC 10, HTC 10 Build/OPR1.170623.027, HTC Desire 10 lifestyle, HTC Desire 530, HTC Desire 626s, HTC Desire 650, HTC One, HTC One A9s, HTC One M9PLUS, HTL23, HUAWEI CUN-L03, HUAWEI G7-L03, HUAWEI RIO-L03, HUAWEI TAG-L13, HUAWEI VNS-L23, HUAWEI VNS-L31, HUAWEI VNS-L53, HUAWEI Y560-L03, Hisense F20, Hisense F23, Hisense F24, Hisense F8 MINI, Hisense Hi 3 Build/NRD90M, Hisense L675, Hisense T963, Hisense U963, IM6, INE-LX2 Build/HUAWEIINE-LX2, INFINIT_1, Ilium L1120, Ilium M3 Build/NRD90M, Ilium X510, Ilium X520, Ilium X710, Infinit MX Build/NRD90M, Infinit_Lite_2, Infinit_X_CAM, Infinity, JKM-LX3, K011 Build/KOT49H, K014, K81, KEMPLER_TV, KFAPWI, KFARWI, KFASWI, KFAUWI, KFDOWI, KFFOWI, KFGIWI, KFKAWI, KFSUWI, KFTBWI, KFTHWI, KFTT, KYOCERA-C6742, KYOCERA-C6742A, L-03K, LAVA_R1, LDN-L21, LDN-LX3, LEX722, LG-D120 Build/KOT49I.V10a, LG-D280, LG-D325, LG-D415, LG-D631, LG-D690, LG-D805, LG-D852, LG-D852G, LG-G710, LG-H500, LG-H542, LG-H631MX, LG-H634, LG-H650, LG-H700, LG-H811, LG-H831, LG-H840, LG-H860, LG-H870, LG-H870DS, LG-H870DS Build/OPR1.170623.032, LG-H872, LG-H873, LG-H873 Build/NRD90U, LG-H910, LG-H918, LG-H930, LG-H931 Build/OPR1.170623.026, LG-H955, LG-H990, LG-K120, LG-K200, LG-K210, LG-K220, LG-K240, LG-K410, LG-K425, LG-K430, LG-K500, LG-K520, LG-K530, LG-K540, LG-K557 Build/MXB48T, LG-K580, LG-LS777, LG-LS993, LG-LS997, LG-LS997 Build/OPR1.170623.032, LG-M151, LG-M153, LG-M210, LG-M250, LG-M320, LG-M327, LG-M400, LG-M430, LG-M700, LG-M700 Build/OPM1.171019.026, LG-M703, LG-M710, LG-Q710AL, LG-TP260, LG-TP450, LG-UK495, LG-US998, LG-V400, LG-V410/V41020e, LG-V530, LG-X150, LG-X165g, LG-X180g, LG-X210, LG-X220, LG-X230, LG-X240, LGL157BL, LGL158VL, LGL164VL, LGL59BL, LGL82VL, LGL84VL, LGLS676, LGLS775, LGMP260, LGMP450, LGMS210, LGMS330, LGMS550, LGUS110, LLD-L21, LLD-L31, LLD-L31 Build/HONORLLD-L31, LM-G710, LM-G710VM, LM-Q610(FGN, LM-Q610.FG, LM-Q710(FGN, LM-Q710.FG, LM-Q710.FGN, LM-Q850, LM-V350, LM-V405, LM-X210, LM-X210 Build/N2G47H, LM-X210CM, LM-X212(G, LM-X410(FG, LM-X410.F, LM-X410PM, LML413DL, LYA-L09, Lenovo A2016b30, Lenovo K33b36, Lenovo P2a42, Lenovo PB2-650Y, Lenovo PB2-670Y, Lenovo TB-7104F Build/O11019, LenovoA3300-GV, Life, Lifesize, Lumia, M4 SS4453, M4 SS4456, M4 SS4457, M4 SS4458, M4 SS4458-R, M4_B2, M4_B3, M5, MB520, MHA-L09, MHA-L29, MI 4W Build/MMB29M, MI MAX 3, MIX, MIX Build/OPR1.170623.032, MXG401, MYA-L03, MYA-L13, Max10, Max10 Build/LMY47I, Mi A1, Mi A1 Build/OPM1.171019.026, Mi A2, Mi A2 Lite, Miracle, Moto C, Moto C Plus, Moto E (4), Moto E (4) Build/NDQ26.69-64-9, Moto E (4) Build/NMA26.42-157, Moto E (4) Build/NMA26.42-167, Moto E (4) Plus, Moto E (4) Plus Build/NMA26.42-162, Moto E (4) Plus Build/NMA26.42-167, Moto G (4), Moto G (4) Build/NPJS25.93-14-8.1-9, Moto G (4) Build/NPJS25.93-14.7-8, Moto G (5), Moto G (5) Build/NPPS25.137-93-12, Moto G (5) Build/NPPS25.137-93-14, Moto G (5) Build/OPP28.85-13, Moto G (5) Build/OPPS28.85-13-2, Moto G (5) Plus, Moto G (5) Plus Build/NPN25.137-35, Moto G (5) Plus Build/NPNS25.137-92-14, Moto G (5) Plus Build/NPNS25.137-93-14, Moto G (5) Plus Build/OPS28.85-13, Moto G (5) Plus Build/OPSS28.85-13-3, Moto G Play, Moto G Play Build/NPIS26.48-43-2, Moto X Play, Moto Z2 Play, Moto Z2 Play Build/NPSS26.118-19-22, Moto Z2 Play Build/OPS27.76-12-25, Moto Z2 Play Build/OPSS27.76-12-25-3, Moto Z2 Play Build/OPSS27.76-12-25-7, Moto Z3 Play, Moto Z3 Play Build/OPW28.70-22, MotoE2, MotoG3 Build/MPIS24.65-33.1-2-10, N1, N5702L, N9137, N9517, N9519, N9560, NATIVO Build/NRD90M, NEM-L51, NX16A11264, NX551J, NX591J, Neffos, Neffos X1 Max, Neffos_C7, Neffos_C9A, Nexus 5, Nexus 5X, Nexus 5X Build/N2G48C, Nexus 5X Build/OPM7.181005.003, Nexus 6P, Nokia, Nokia 2 Build/NMF26F, Nokia 6.1 Build/OPR1.170623.026, Nokia_X, Note8, ONEPLUS A3000, ONEPLUS A3003, ONEPLUS A3003 Build/OPR1.170623.032, ONEPLUS A3010, ONEPLUS A5000, ONEPLUS A5000 Build/OPM1.171019.011, ONEPLUS A5010, ONEPLUS A6003, ONEPLUS A6003 Build/PKQ1.180716.001, ONEPLUS A6013, ONIX, Orange_Rise_33, P002, P008, P00I, P10, P5047A, P5525A, P5526A, PAR-LX9, PIC-LX9, POCOPHONE, PRA-LX1, PRA-LX2, PRA-LX3, PSPC550, PSPCL20A0, PSPCM20A0, Phone, Pixel 2, Pixel 2 Build/OPM2.171026.006.C1, Pixel 2 Build/OPM2.171026.006.G1, Pixel 2 Build/PPR1.180610.009, Pixel 2 Build/PPR2.180905.005, Pixel 2 Build/PPR2.181005.003, Pixel 2 XL, Pixel 2 XL Build/OPM2.171026.006.H1, Pixel 2 XL Build/PPR2.180905.005, Pixel 2 XL Build/PPR2.181005.003, Pixel 3, Pixel 3 XL, Pixel Build/OPM4.171019.021.P1, Pixel XL, Pixel XL Build/OPM4.171019.021.P1, Pixel XL Build/PPR2.181005.003, Polaroid, Power_2, Q01A, Q05A, QMV7B, R505, R7plusf, R8006, RAINBOW, RCT6103W46, RCT6303W87M7, RCT6513W87, RCT6873W42M, RCT6873W42M_F7, RCT6973W43MD, RCT6B03W13, RIDGE, RIM, RNE-L03, RNE-L21, RNE-L22, RNE-L23, ROCKET, Redmi 4A, Redmi 4X, Redmi 5 Plus, Redmi 5 Plus Build/OPM1.171019.019, Redmi 5A Build/N2G47H, Redmi 6, Redmi 6A, Redmi Note 3, Redmi Note 3 Build/NMF26Q, Redmi Note 4, Redmi Note 5, Redmi Note 5 Build/OPM1.171019.011, Redmi Note 5A, Redmi Note 6 Pro, Redmi S2, Rex Build/MRA58K, S60, S60 Lite Build/NRD90M, S8, S9+, SAMSUNG SM-A320FL Build/R16NW, SAMSUNG SM-A520F Build/R16NW, SAMSUNG SM-A520W Build/NRD90M, SAMSUNG SM-A530F Build/NMF26X, SAMSUNG SM-A530F Build/R16NW, SAMSUNG SM-A605GN Build/R16NW, SAMSUNG SM-G390F Build/NRD90M, SAMSUNG SM-G532F Build/MMB29T, SAMSUNG SM-G610M Build/M1AJQ, SAMSUNG SM-G900M Build/MMB29M, SAMSUNG SM-G930A Build/R16NW, SAMSUNG SM-G930F Build/R16NW, SAMSUNG SM-G930P Build/R16NW, SAMSUNG SM-G930T Build/R16NW, SAMSUNG SM-G935A Build/R16NW, SAMSUNG SM-G935F Build/R16NW, SAMSUNG SM-G935T Build/R16NW, SAMSUNG SM-G960F Build/R16NW, SAMSUNG SM-G960U1 Build/R16NW, SAMSUNG SM-J330FN Build/NRD90M, SAMSUNG SM-J400M Build/R16NW, SAMSUNG SM-J510FN Build/NMF26X, SAMSUNG SM-J510MN Build/NMF26X, SAMSUNG SM-J600G Build/R16NW, SAMSUNG SM-J610G Build/M1AJQ, SAMSUNG SM-J737P Build/R16NW, SAMSUNG SM-J737T Build/R16NW, SAMSUNG SM-J810M Build/R16NW, SAMSUNG SM-N910F/N910FXXU1DQL2 Build/MMB29M, SAMSUNG SM-N950F Build/R16NW, SAMSUNG SM-N950N Build/R16NW, SAMSUNG SM-N960U Build/M1AJQ, SAMSUNG SM-P900 Build/LRX22G, SAMSUNG SM-T377W Build/NMF26X, SAMSUNG SM-T580 Build/M1AJQ, SAMSUNG SM-T820 Build/R16NW, SAMSUNG-SM-G530A, SAMSUNG-SM-G530AZ, SAMSUNG-SM-G870A Build/LRX21T, SAMSUNG-SM-G891A, SAMSUNG-SM-G891A Build/R16NW, SAMSUNG-SM-G920A, SAMSUNG-SM-G928A, SAMSUNG-SM-G930A Build/R16NW, SAMSUNG-SM-J320A, SAMSUNG-SM-J321AZ, SAMSUNG-SM-J327A, SAMSUNG-SM-J727A, SAMSUNG-SM-N915A Build/KTU84P, SAMSUNG-SM-T337A, SC-03K, SCH-I545, SGH-T999L, SGP311, SGP512, SGP621, SH-01K, SHIFT4.2, SHV39, SL729, SLA-L03, SM-A300FU, SM-A310F, SM-A320F, SM-A320FL, SM-A320FL Build/R16NW, SM-A500M, SM-A5100, SM-A510F, SM-A510M, SM-A520F, SM-A520W Build/R16NW, SM-A530F, SM-A530F Build/R16NW, SM-A530W, SM-A600FN, SM-A600T1, SM-A605GN, SM-A605GN Build/R16NW, SM-A700K, SM-A720F, SM-A730F, SM-A750G, SM-A920F, SM-C5010, SM-G316M, SM-G355M, SM-G357FZ, SM-G357M, SM-G360P, SM-G386F, SM-G530H, SM-G531H, SM-G532G, SM-G532M, SM-G532MT, SM-G550T1, SM-G570M, SM-G570M Build/R16NW, SM-G600S, SM-G610M, SM-G610M Build/M1AJQ, SM-G611F, SM-G800F, SM-G800M, SM-G850F, SM-G892U, SM-G892U Build/R16NW, SM-G900F, SM-G900F Build/NJH47F, SM-G900H, SM-G900M, SM-G900T, SM-G900T Build/LMY47X, SM-G903F, SM-G920F, SM-G920R7, SM-G925F, SM-G925P, SM-G925T, SM-G925V, SM-G928T, SM-G930F, SM-G930F Build/R16NW, SM-G930P Build/R16NW, SM-G930R4, SM-G930R4 Build/R16NW, SM-G930T Build/R16NW, SM-G930U, SM-G930U Build/R16NW, SM-G930V, SM-G930V Build/R16NW, SM-G930VC, SM-G930VL, SM-G930W8, SM-G930W8 Build/R16NW, SM-G935F, SM-G935F Build/R16NW, SM-G935P, SM-G935R4, SM-G935S, SM-G935T Build/R16NW, SM-G935V Build/R16NW, SM-G950, SM-G9500, SM-G950F, SM-G950N, SM-G950U, SM-G950U1, SM-G955N, SM-G955U, SM-G955U1, SM-G9600, SM-G960F, SM-G960N, SM-G960U, SM-G960U1, SM-G960W, SM-G9650, SM-G965F, SM-G965U, SM-G965U1, SM-J105B, SM-J106B, SM-J111M, SM-J120FN, SM-J120H, SM-J200G Build/LMY47X, SM-J200M, SM-J250F, SM-J250M, SM-J260M, SM-J320F, SM-J320FN, SM-J320M, SM-J320V, SM-J327P, SM-J327T, SM-J327T1, SM-J327U, SM-J327V, SM-J327VPP, SM-J327W, SM-J330FN, SM-J337A, SM-J337T, SM-J337V, SM-J400F, SM-J400M, SM-J400M Build/R16NW, SM-J415G, SM-J500F, SM-J500M, SM-J510H, SM-J510MN, SM-J530F, SM-J530GM, SM-J530L, SM-J600FN, SM-J600G, SM-J600G Build/R16NW, SM-J600GT, SM-J610G, SM-J700H, SM-J700M, SM-J700T, SM-J701F, SM-J701M, SM-J701MT, SM-J710F, SM-J710MN, SM-J720F, SM-J727R4, SM-J727T, SM-J727T1, SM-J727U, SM-J727V, SM-J730G, SM-J730GM, SM-J737P, SM-J737P Build/R16NW, SM-J737T, SM-J737V, SM-J810M, SM-J810M Build/R16NW, SM-J810Y, SM-N7505, SM-N900, SM-N900P, SM-N900V, SM-N900W8, SM-N910C, SM-N910T, SM-N910V, SM-N915T, SM-N9200, SM-N920C, SM-N920F, SM-N920G, SM-N920I, SM-N950F, SM-N950U, SM-N950U1, SM-N9600, SM-N9600 Build/M1AJQ, SM-N960F, SM-N960U, SM-N960U Build/M1AJQ, SM-N960U1, SM-N960W, SM-P350, SM-P555M, SM-P580, SM-P905V, SM-S337TL, SM-S367VL, SM-S727VL, SM-S737TL, SM-T110, SM-T113NU, SM-T217T, SM-T280, SM-T320, SM-T337T, SM-T350, SM-T357W, SM-T360, SM-T378V, SM-T385M, SM-T387V, SM-T530NU, SM-T560, SM-T560NU, SM-T597V, SM-T677V, SM-T700, SM-T710, SM-T713, SM-T805 Build/MMB29K, SM-T813, SM-T817V, SM-T820, SM-T827V, SM-T837V, SM-T900, SNE-LX3, SO-02H, STUDIO, Shift, Shock, Slate, T09, T1-A21w, TA-1021 Build/OPR1.170623.026, TA-1028, TA-1033, TA-1039, TA-1039 Build/OPR1.170623.026, TR10RS1, TRT-L53, TRT-LX2, TU20402-58, Tab8, Tank, TechPad_10Y, U2, U972, ULTRA, UNIQ, VF-895N, VIE-L09, VIE-L29, VK410, VKY-L09, VKY-L29, VORAGO, VS501, VS986, VS987, VS988, VS988 Build/OPR1.170623.032, VS990, VS995, VTR-L09, WAS-LX1A, WAS-LX3, XT1053, XT1562, XT1562 Build/MPDS24.107-52-11, XT1572, XT1585, XT1635-02 Build/OPNS27.76-12-22-3, XT1635-02 Build/OPNS27.76-12-22-9, XT1650 Build/OCLS27.76-69-6, Y635-L03, Z730, Z818L, Z851M, Z899VL, Z9, Z916BL, Z956, Z957, Z981, Z982, Z988, ZEI403, ZTE BLADE A0620 Build/NMF26F, ZTE BLADE A6, ZTE BLADE V8 MINI, ZTE-K88, ZTE-Z999, Zebra, a500, arc, aura, breeze, carbon_harpia, es-es, gxq6580_weg_l, hi6210sft, hi6250, hi6250 Build/MRA58K, i50F Build/NRD90M, iPhone 6plus, iris, moto e5, moto e5 Build/OPP27.91-146, moto e5 Build/OPP27.91-25, moto e5 Build/OPP27.91-72, moto e5 cruise, moto e5 play, moto e5 play Build/OCPS27.91-51-3-3, moto e5 play Build/OPG28.54-19, moto e5 play Build/OPGS28.54-19-2, moto e5 plus, moto e5 plus Build/OPP27.91-122, moto g(6), moto g(6) Build/OPS27.82-41, moto g(6) Build/OPS27.82-72, moto g(6) Build/OPS27.82-87, moto g(6) Build/OPSS27.82-87-3, moto g(6) play, moto g(6) play Build/OPP27.91-140, moto g(6) play Build/OPP27.91-143, moto g(6) play Build/OPP27.91-87, moto g(6) plus, moto g(6) plus Build/OPW27.113-89, moto g(6) plus Build/OPWS27.113-25-4, moto g(6) plus Build/OPWS27.113-89-2, moto x4, moto x4 Build/OPWS27.57-40-17, moto x4 Build/OPWS27.57-40-22, moto z3, motorola, motorola one, rv:21.0, rv:26.0, rv:27.0, rv:28.0, rv:36.0, rv:60.1.0, rv:62.0, rv:63.0, rv:64.0, rv:65.0, verykoolS5027, verykool_s5516, verykools5036, verykools5702, weimei_we]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:70: UserWarning: Test/Validation dataset column 'id_33' has levels not trained on: [1000x798, 1021x669, 1024x576, 1024x820, 1025x640, 1080x675, 1151x719, 1151x863, 1151x864, 1151x921, 1152x672, 1152x922, 1208x720, 1223x691, 1231x358, 1260x787, 1264x945, 1265x948, 1268x862, 1272x952, 1279x719, 1279x720, 1279x767, 1279x768, 1279x799, 1279x800, 1280x767, 1280x799, 1280x801, 1281x1024, 1281x769, 1296x810, 1344x720, 1359x767, 1360x765, 1361x768, 1364x767, 1366x766, 1366x769, 1368x912, 1399x1050, 1408x1126, 1408x1127, 1408x844, 1416x758, 1416x805, 1466x403, 1480x721, 1500x1000, 1500x840, 1501x843, 1501x844, 1536x1024, 1537x865, 1592x828, 1599x1200, 1600x1280, 1600x868, 1600x901, 1601x900, 1621x1081, 1622x1081, 1624x750, 1669x942, 1679x1050, 1679x987, 1680x1018, 1681x1050, 1720x947, 1722x1440, 1727x1079, 1767x991, 1792x768, 1792x828, 1794x1080, 1800x1200, 1800x1440, 1842x1047, 1862x1048, 1918x1078, 1918x1347, 1919x1279, 1919x1280, 1920x1017, 1920x1128, 1920x1199, 1920x1440, 1920x974, 1920x983, 1921x1200, 1926x921, 2047x1152, 2047x1279, 2048x1151, 2048x1537, 2052x1368, 2094x1080, 2112x1320, 2133x1080, 2160x1920, 2161x1080, 2162x1081, 2162x1082, 2188x1459, 2241x1080, 2241x1081, 2255x1504, 2257x1505, 2281x1081, 2303x1295, 2303x1439, 2340x1080, 2341x1080, 2341x1081, 2388x1668, 2390x1344, 2398x1599, 2399x1348, 2399x1598, 2401x1350, 2401x1351, 2462x1641, 2463x1642, 2556x1248, 2559x1079, 2559x1080, 2559x1599, 2560x1079, 2560x1313, 2560x1418, 2560x1439, 2560x1441, 2560x1599, 2561x1312, 2562x1314, 2562x1440, 2562x1441, 2592x1728, 2646x1440, 2680x1440, 2688x1242, 2696x1440, 2699x1799, 2703x1441, 2734x1824, 2735x1824, 2768x1440, 2789x1442, 2791x1440, 2880x1920, 2928x1440, 2950x1440, 2960x1442, 2999x1998, 3000x1687, 3000x1999, 3011x2007, 3120x1440, 3122x1442, 3123x1440, 3168x1980, 3199x1799, 3200x1799, 3200x1801, 3201x1799, 3239x2159, 3239x2160, 3241x2161, 3280x2048, 3439x1440, 3521x1980, 3584x2016, 3784x1584, 3839x1599, 3839x2158, 3840x1599, 3840x2159, 3840x2161, 3841x2401, 4096x2160, 4096x3072, 4225x2377, 4300x1800, 4320x2700, 4500x3001, 455x256, 4608x2592, 4800x2700, 5960x1080, 6144x3456, 683x384, 7680x4320, 792x480, 800x480, 8640x1620, 888x540, 8960x5040, 910x512, 960x480, 960x600, 993x664]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:70: UserWarning: Test/Validation dataset column 'id_31' has levels not trained on: [blackberry, chrome 39.0 for android, chrome 67.0 for ios, chrome 68.0, chrome 68.0 for android, chrome 68.0 for ios, chrome 69.0 for android, chrome 69.0 for ios, chrome 70.0, chrome 70.0 for android, chrome 70.0 for ios, chrome 71.0, chrome 71.0 for android, chrome 71.0 for ios, edge 18.0, firefox 61.0, firefox 62.0, firefox 63.0, firefox 64.0, firefox mobile 62.0, firefox mobile 63.0, google search application 52.0, google search application 54.0, google search application 56.0, google search application 58.0, google search application 59.0, google search application 60.0, google search application 61.0, google search application 62.0, google search application 63.0, google search application 64.0, google search application 65.0, mobile safari 12.0, opera 54.0, opera 55.0, opera 56.0, rim, safari 12.0, samsung browser 7.2, samsung browser 7.4, samsung browser 8.2, uc]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:70: UserWarning: Test/Validation dataset column 'id_30' has levels not trained on: [Android 9, Mac OS X 10.14, Mac OS X 10_13_6, Mac OS X 10_14, Mac OS X 10_14_0, Mac OS X 10_14_1, Mac OS X 10_14_2, iOS 12.0.0, iOS 12.0.1, iOS 12.1.0, iOS 12.1.1, iOS 12.1.2]\n",
      "  warnings.warn(w)\n",
      "/opt/conda/lib/python3.6/site-packages/h2o/job.py:70: UserWarning: Test/Validation dataset column 'P_emaildomain' has levels not trained on: [scranton.edu]\n",
      "  warnings.warn(w)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 528 ms, sys: 140 ms, total: 668 ms\n",
      "Wall time: 18.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(506691,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_preds = aml.predict(X_test)\n",
    "y_preds['p1'].as_data_frame().values.flatten().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 108 ms, sys: 4 ms, total: 112 ms\n",
      "Wall time: 116 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import pandas as pd\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.92 s, sys: 296 ms, total: 4.22 s\n",
      "Wall time: 4.65 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample_submission['isFraud'] = y_preds['p1'].as_data_frame().values\n",
    "sample_submission.to_csv('H2O_AutoML_submission_1.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
